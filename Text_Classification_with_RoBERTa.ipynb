{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification with RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eff57e3f9324442a8dc2b677ef40d336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65d03e7e9c34496ba987f7935e26e9c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_48375d9934964f6ea4220b83ed47ceb0",
              "IPY_MODEL_b08ea40fe7b9467aa62a650297440ac3"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "65d03e7e9c34496ba987f7935e26e9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "48375d9934964f6ea4220b83ed47ceb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b2598f964a042aeb02c821aed6cd41b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96ae8f6da95b4de18987da17a978943c"
          },
          "model_module_version": "1.5.0"
        },
        "b08ea40fe7b9467aa62a650297440ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7df8fd11dba4eb2a4ebea170c6a70f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 853kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_712843f81fed42cda53d88cad7626dfd"
          },
          "model_module_version": "1.5.0"
        },
        "0b2598f964a042aeb02c821aed6cd41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "96ae8f6da95b4de18987da17a978943c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "c7df8fd11dba4eb2a4ebea170c6a70f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "712843f81fed42cda53d88cad7626dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "442644a692d148da920516f767839679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_324d1bdc7c60480faa058ea6c3270f80",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bb1222224ce44e08c175f9d3d813ee4",
              "IPY_MODEL_6aa74071b84c421a830443b3887d07d8"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "324d1bdc7c60480faa058ea6c3270f80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "0bb1222224ce44e08c175f9d3d813ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4cea5827f6c46ba9253607772912e0b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7755b3d3b10c48d8beda1a4a0cd6f443"
          },
          "model_module_version": "1.5.0"
        },
        "6aa74071b84c421a830443b3887d07d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb8aa11e86a84d8d9e6dfbbe0dc062f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:02&lt;00:00, 194kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1abcfd556d51438daa784c2f76f89cea"
          },
          "model_module_version": "1.5.0"
        },
        "f4cea5827f6c46ba9253607772912e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "7755b3d3b10c48d8beda1a4a0cd6f443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "fb8aa11e86a84d8d9e6dfbbe0dc062f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "1abcfd556d51438daa784c2f76f89cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "574d693ae1504507a2ec6ea4c4f82186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c764e7dca8fa4a9e93ced81f6ff150b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_898fbef6d2fe4ce089177204bad8d037",
              "IPY_MODEL_6989ea817d094911ac132710858bfc19"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "c764e7dca8fa4a9e93ced81f6ff150b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "898fbef6d2fe4ce089177204bad8d037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d33dfccf37f24283b8f47c0ed2be5577",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9484067921446dd87a04b286db53397"
          },
          "model_module_version": "1.5.0"
        },
        "6989ea817d094911ac132710858bfc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ebfd1d5b74694affb74466f0e7b03a6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.41MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19bd86e4b48f4a138b3188f1c5ad53fb"
          },
          "model_module_version": "1.5.0"
        },
        "d33dfccf37f24283b8f47c0ed2be5577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "b9484067921446dd87a04b286db53397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "ebfd1d5b74694affb74466f0e7b03a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "19bd86e4b48f4a138b3188f1c5ad53fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKqMMDpA1H7G"
      },
      "source": [
        "## Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ6tKSBCuSo3"
      },
      "source": [
        "To create appropriate datasets, I did some basic operations on the given CSV files and created two datasets with the names \"TrainData\" and \"TestData\". I used pre-trained transfer models and since the data pre-processing operations are handled inside these models, the only pre-processing that I used is removing the punctuations. \n",
        "\n",
        "---\n",
        "\n",
        "Below is a summary of my two best submission scores on [this Kaggle public leaderboard](https://www.kaggle.com/competitions/math80600aw21/leaderboard?tab=public). The two pre-trained models have been fine-tuned. In this document, I have provided only the code for the first model (\"roberta-large\") as it has given the best test accuracy. \n",
        "\n",
        "\n",
        "\n",
        "|   Model       |Max_Len|batch_size| lr |eps |epochs|avg train loss|validation accuracy|submission score|\n",
        "|---------------|-------|----------|----|----|------|--------------|-------------------|----------------|\n",
        "| roberta_large |  300  |     10   |1e-5|1e-6|  4   |     0.23     |     0.8502        |     0.85982    |\n",
        "| deberta_large |  256  |     6    |1e-5|1e-8|  4   |     0.18     |     0.8528        |     0.85784    |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Zikeaoo0tg",
        "outputId": "2e824911-752a-4edd-a565-7e0dc1666741"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrYp0vb2e6bz"
      },
      "source": [
        "## Set hyper-parameters\n",
        "## These values have been chosen based on my best results, considering the limitations of the cuda memory. \n",
        "seed_val = 67\n",
        "Max_Len = 300\n",
        "batch_size = 10\n",
        "epochs = 4\n",
        "lr = 1e-5\n",
        "eps = 1e-6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBgFq9Tw3dVD"
      },
      "source": [
        "## Loading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Im05x9Ss1m",
        "outputId": "1e502ff6-1a10-4d03-db99-b65853cfdbca"
      },
      "source": [
        "## Read \"TrainData.csv\" from the respective folder on your Google Drive\"\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Kaggle-Bahareh/TrainData.csv\", error_bad_lines=False)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>nodeid</th>\n",
              "      <th>paperid</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>9657784</td>\n",
              "      <td>evasion attacks against machine learning at te...</td>\n",
              "      <td>In security-sensitive applications, the succes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>39886162</td>\n",
              "      <td>how hard is computing parity with noisy commun...</td>\n",
              "      <td>We show a tight lower bound of $\\Omega(N \\log\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>121432379</td>\n",
              "      <td>a promise theory perspective on data networks</td>\n",
              "      <td>Networking is undergoing a transformation thro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1444859417</td>\n",
              "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
              "      <td>This paper shows the WEBVRGIS platform overlyi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1483430697</td>\n",
              "      <td>information theoretic authentication and secre...</td>\n",
              "      <td>In the splitting model, information theoretic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>5</td>\n",
              "      <td>137822</td>\n",
              "      <td>2342249457</td>\n",
              "      <td>incentivizing users of data centers participat...</td>\n",
              "      <td>Demand response is widely employed by todayâ€™...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>16</td>\n",
              "      <td>137823</td>\n",
              "      <td>2343427588</td>\n",
              "      <td>semantic change detection with hypermaps</td>\n",
              "      <td>Change detection is the study of detecting cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>9</td>\n",
              "      <td>137827</td>\n",
              "      <td>2347853400</td>\n",
              "      <td>computing with polynomial ordinary differentia...</td>\n",
              "      <td>In 1941, Claude Shannon introduced the General...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>8</td>\n",
              "      <td>137830</td>\n",
              "      <td>2399648051</td>\n",
              "      <td>on energy efficiency in wireless networks a ga...</td>\n",
              "      <td>We develop a game-theoretic framework to inves...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>2</td>\n",
              "      <td>137831</td>\n",
              "      <td>2400572038</td>\n",
              "      <td>incorporating quotation and evaluation into ch...</td>\n",
              "      <td>${\\rm \\small CTT}_{\\rm qe}$ is a version of Ch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  ...                                           abstract\n",
              "0          4  ...  In security-sensitive applications, the succes...\n",
              "1          5  ...  We show a tight lower bound of $\\Omega(N \\log\\...\n",
              "2          8  ...  Networking is undergoing a transformation thro...\n",
              "3          6  ...  This paper shows the WEBVRGIS platform overlyi...\n",
              "4          4  ...  In the splitting model, information theoretic ...\n",
              "...      ...  ...                                                ...\n",
              "59995      5  ...  Demand response is widely employed by todayâ€™...\n",
              "59996     16  ...  Change detection is the study of detecting cha...\n",
              "59997      9  ...  In 1941, Claude Shannon introduced the General...\n",
              "59998      8  ...  We develop a game-theoretic framework to inves...\n",
              "59999      2  ...  ${\\rm \\small CTT}_{\\rm qe}$ is a version of Ch...\n",
              "\n",
              "[60000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZx9KIcAcAi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f424a4ba-8d82-47e4-e343-6bb8ca2d1e7d"
      },
      "source": [
        "## Read \"TestData.csv\" from the respective folder on your Google Drive\"\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Kaggle-Bahareh/TestData.csv\", error_bad_lines=False)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodeid</th>\n",
              "      <th>paperid</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>137832</td>\n",
              "      <td>2403725649</td>\n",
              "      <td>patchlift fast and exact computation of patch ...</td>\n",
              "      <td>In this paper, we propose a fast algorithm cal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>137833</td>\n",
              "      <td>2404740077</td>\n",
              "      <td>the unreasonable effectiveness of address clus...</td>\n",
              "      <td>Address clustering tries to construct the one-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>137834</td>\n",
              "      <td>2407125866</td>\n",
              "      <td>end to end goal driven web navigation</td>\n",
              "      <td>We propose a goal-driven web navigation as a b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>137836</td>\n",
              "      <td>2408327416</td>\n",
              "      <td>complexity measures for map reduce and compari...</td>\n",
              "      <td>The programming paradigm Map-Reduce and its ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137837</td>\n",
              "      <td>2412021890</td>\n",
              "      <td>a parallel implementation of the ensemble kalm...</td>\n",
              "      <td>This paper discusses an efficient parallel imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13713</th>\n",
              "      <td>169336</td>\n",
              "      <td>3011349285</td>\n",
              "      <td>confidence guided stereo 3d object detection w...</td>\n",
              "      <td>Accurate and reliable 3D object detection is v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13714</th>\n",
              "      <td>169338</td>\n",
              "      <td>3011696425</td>\n",
              "      <td>sentinet detecting localized universal attacks...</td>\n",
              "      <td>SentiNet is a novel detection framework for lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13715</th>\n",
              "      <td>169340</td>\n",
              "      <td>3011798063</td>\n",
              "      <td>learning compositional rules via neural progra...</td>\n",
              "      <td>Many aspects of human reasoning, including lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13716</th>\n",
              "      <td>169341</td>\n",
              "      <td>3012226457</td>\n",
              "      <td>certified defenses for adversarial patches</td>\n",
              "      <td>Adversarial patch attacks are among one of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13717</th>\n",
              "      <td>169342</td>\n",
              "      <td>3012505757</td>\n",
              "      <td>fauras a proxy based framework for ensuring th...</td>\n",
              "      <td>HTTP/2 video streaming has caught a lot of att...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13718 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       nodeid  ...                                           abstract\n",
              "0      137832  ...  In this paper, we propose a fast algorithm cal...\n",
              "1      137833  ...  Address clustering tries to construct the one-...\n",
              "2      137834  ...  We propose a goal-driven web navigation as a b...\n",
              "3      137836  ...  The programming paradigm Map-Reduce and its ma...\n",
              "4      137837  ...  This paper discusses an efficient parallel imp...\n",
              "...       ...  ...                                                ...\n",
              "13713  169336  ...  Accurate and reliable 3D object detection is v...\n",
              "13714  169338  ...  SentiNet is a novel detection framework for lo...\n",
              "13715  169340  ...  Many aspects of human reasoning, including lan...\n",
              "13716  169341  ...  Adversarial patch attacks are among one of the...\n",
              "13717  169342  ...  HTTP/2 video streaming has caught a lot of att...\n",
              "\n",
              "[13718 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrWAA--iSuFe"
      },
      "source": [
        "## Data PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "zkbmbP_CSs1n",
        "outputId": "06b3a75b-045e-43b8-c45e-171c8f6ef93f"
      },
      "source": [
        "## TrainData\n",
        "## concatenation of \"title\" and \"abstract\" columns and removing other columns except for \"label\" column\n",
        "df['text'] = df.iloc[:, 3] + \" \" + df.iloc[:, 4]\n",
        "df = df.drop(df.columns[[1,2,3,4]], axis=1)\n",
        "df = df[['text', 'label']]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>evasion attacks against machine learning at te...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how hard is computing parity with noisy commun...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a promise theory perspective on data networks ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>information theoretic authentication and secre...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>incentivizing users of data centers participat...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>semantic change detection with hypermaps Chang...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>computing with polynomial ordinary differentia...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>on energy efficiency in wireless networks a ga...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>incorporating quotation and evaluation into ch...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "0      evasion attacks against machine learning at te...      4\n",
              "1      how hard is computing parity with noisy commun...      5\n",
              "2      a promise theory perspective on data networks ...      8\n",
              "3      webvrgis based city bigdata 3d visualization a...      6\n",
              "4      information theoretic authentication and secre...      4\n",
              "...                                                  ...    ...\n",
              "59995  incentivizing users of data centers participat...      5\n",
              "59996  semantic change detection with hypermaps Chang...     16\n",
              "59997  computing with polynomial ordinary differentia...      9\n",
              "59998  on energy efficiency in wireless networks a ga...      8\n",
              "59999  incorporating quotation and evaluation into ch...      2\n",
              "\n",
              "[60000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "3pOXNALel-iQ",
        "outputId": "77a76460-2569-4793-84a5-85e140cbfa7d"
      },
      "source": [
        "## TestData \n",
        "## concatenation of \"title\" and \"abstract\" columns and removing other columns \n",
        "df2['text'] = df2.iloc[:, 2] + \" \" + df2.iloc[:, 3]\n",
        "df2 = df2.drop(df2.columns[[0,1,2,3]], axis=1)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>patchlift fast and exact computation of patch ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the unreasonable effectiveness of address clus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>end to end goal driven web navigation We propo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>complexity measures for map reduce and compari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a parallel implementation of the ensemble kalm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13713</th>\n",
              "      <td>confidence guided stereo 3d object detection w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13714</th>\n",
              "      <td>sentinet detecting localized universal attacks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13715</th>\n",
              "      <td>learning compositional rules via neural progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13716</th>\n",
              "      <td>certified defenses for adversarial patches Adv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13717</th>\n",
              "      <td>fauras a proxy based framework for ensuring th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13718 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "0      patchlift fast and exact computation of patch ...\n",
              "1      the unreasonable effectiveness of address clus...\n",
              "2      end to end goal driven web navigation We propo...\n",
              "3      complexity measures for map reduce and compari...\n",
              "4      a parallel implementation of the ensemble kalm...\n",
              "...                                                  ...\n",
              "13713  confidence guided stereo 3d object detection w...\n",
              "13714  sentinet detecting localized universal attacks...\n",
              "13715  learning compositional rules via neural progra...\n",
              "13716  certified defenses for adversarial patches Adv...\n",
              "13717  fauras a proxy based framework for ensuring th...\n",
              "\n",
              "[13718 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNfXuhHsxUub",
        "outputId": "4d5ec788-0392-4cbb-e8b7-19c0d053241a"
      },
      "source": [
        "## A function to remove punctuations and other symbols\n",
        "import string\n",
        "\n",
        "punct =[]\n",
        "punct += list(string.punctuation)\n",
        "punct += '’'\n",
        "punct.remove(\"'\")\n",
        "def remove_punctuations(text):\n",
        "    for punctuation in punct:\n",
        "        text = text.replace(punctuation, ' ')\n",
        "    return text\n",
        "print(punct)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '’']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "jqHKF-m2Ss1n",
        "outputId": "be93576b-ed30-4f63-aa39-f13898dc9a39"
      },
      "source": [
        "## Remove punctuations from \"text\" data column of TrainData\n",
        "\n",
        "df['text'] = df['text'].apply(remove_punctuations)\n",
        "df['text'] = df['text'].apply(lambda x: str(x).replace(\"  \", \" \"))\n",
        "df.to_csv('TrainData_removed_punctuations.csv')\n",
        "\n",
        "## Looking at an example\n",
        "df['text'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"evasion attacks against machine learning at test time In security sensitive applications the success of machine learning depends on a thorough vetting of their resistance to adversarial data In one pertinent well motivated attack scenario an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples In this work we present a simple but effective gradient based approach that can be exploited to systematically assess the security of several widely used classification algorithms against evasion attacks Following a recently proposed framework for security evaluation we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker's knowledge of the system and her ability to manipulate attack samples This gives the classifier designer a better picture of the classifier performance under evasion attacks and allows him to perform a more informed model selection or parameter setting  We evaluate our approach on the relevant security task of malware detection in PDF files and show that such systems can be easily evaded We also sketch some countermeasures suggested by our analysis \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "P9vxDLUOxrC1",
        "outputId": "d1d4a1ed-6b92-4ffa-cb17-38b648e069b7"
      },
      "source": [
        "## Remove punctuations from \"text\" data column of TestData\n",
        "\n",
        "df2['text'] = df2['text'].apply(remove_punctuations)\n",
        "df2['text'] = df2['text'].apply(lambda x: str(x).replace(\"  \", \" \"))\n",
        "df2.to_csv('TestData_removed_punctuations.csv')\n",
        "\n",
        "## Looking at an example\n",
        "df2['text'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'patchlift fast and exact computation of patch distances using lifting with applications to non local means In this paper we propose a fast algorithm called PatchLift for computing distances between patches extracted from a one dimensional signal PatchLift is based on the observation that the patch distances can be expressed in terms of simple moving sums of an image which is derived from the one dimensional signal via lifting We apply PatchLift to develop a separable extension of the classical Non Local Means NLM algorithm which is at least 100 times faster than NLM for standard parameter settings The PSNR obtained using the proposed extension is typically close to and often larger than the PSNRs obtained using the original NLM We provide some simulations results to demonstrate the acceleration achieved using separability and PatchLift '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njeWCQlB3tfV"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1KjvAXY4r95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e226f4aa-10a7-44b8-ef00-55ddc6b35993"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from google.colab import output\n",
        "\n",
        "## install the transformers package from Hugging Face\n",
        "!pip install transformers\n",
        "output.clear() \n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gucW0c_FbG2"
      },
      "source": [
        "To fine-tune the pre-trained RoBERTa model for solving this text classification problem, we need to split each text into the tokens and for this, we have to use the tokenizer provided by the model.\n",
        "The tokenizer of the model splits the texts into tokens and then adds the special [CLS] and [SEP] tokens. In the end, it maps the tokens to their index in the tokenizer vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "eff57e3f9324442a8dc2b677ef40d336",
            "65d03e7e9c34496ba987f7935e26e9c8",
            "48375d9934964f6ea4220b83ed47ceb0",
            "b08ea40fe7b9467aa62a650297440ac3",
            "0b2598f964a042aeb02c821aed6cd41b",
            "96ae8f6da95b4de18987da17a978943c",
            "c7df8fd11dba4eb2a4ebea170c6a70f2",
            "712843f81fed42cda53d88cad7626dfd",
            "442644a692d148da920516f767839679",
            "324d1bdc7c60480faa058ea6c3270f80",
            "0bb1222224ce44e08c175f9d3d813ee4",
            "6aa74071b84c421a830443b3887d07d8",
            "f4cea5827f6c46ba9253607772912e0b",
            "7755b3d3b10c48d8beda1a4a0cd6f443",
            "fb8aa11e86a84d8d9e6dfbbe0dc062f1",
            "1abcfd556d51438daa784c2f76f89cea",
            "574d693ae1504507a2ec6ea4c4f82186",
            "c764e7dca8fa4a9e93ced81f6ff150b5",
            "898fbef6d2fe4ce089177204bad8d037",
            "6989ea817d094911ac132710858bfc19",
            "d33dfccf37f24283b8f47c0ed2be5577",
            "b9484067921446dd87a04b286db53397",
            "ebfd1d5b74694affb74466f0e7b03a6f",
            "19bd86e4b48f4a138b3188f1c5ad53fb"
          ]
        },
        "id": "qWL6hog24ukn",
        "outputId": "336770f0-49b2-41d5-c49e-5491456b7823"
      },
      "source": [
        "## Tokenize the texts and map them to their index\n",
        "\n",
        "from transformers import RobertaTokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "texts = df.text.values\n",
        "labels = df.label.values\n",
        "\n",
        "input_ids = []\n",
        "for text in texts:\n",
        "    encoded_text = tokenizer.encode(text, add_special_tokens = True,)\n",
        "    input_ids.append(encoded_text)\n",
        "\n",
        "## looking at an example\n",
        "print('text:', texts[3])\n",
        "print('Tokenized text:', tokenizer.tokenize(texts[3]))\n",
        "print('input IDs:', input_ids[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eff57e3f9324442a8dc2b677ef40d336",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "442644a692d148da920516f767839679",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "574d693ae1504507a2ec6ea4c4f82186",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "text: webvrgis based city bigdata 3d visualization and analysis This paper shows the WEBVRGIS platform overlying multiple types of data about Shenzhen over a 3d globe The amount of information that can be visualized with this platform is overwhelming and the GIS based navigational scheme allows to have great flexibility to access the different available data sources For example visualising historical and forecasted passenger volume at stations could be very helpful when overlaid with other social data \n",
            "Tokenized text: ['web', 'vr', 'g', 'is', 'Ġbased', 'Ġcity', 'Ġbig', 'data', 'Ġ3', 'd', 'Ġvisualization', 'Ġand', 'Ġanalysis', 'ĠThis', 'Ġpaper', 'Ġshows', 'Ġthe', 'ĠWE', 'B', 'VR', 'G', 'IS', 'Ġplatform', 'Ġover', 'lying', 'Ġmultiple', 'Ġtypes', 'Ġof', 'Ġdata', 'Ġabout', 'ĠShen', 'zhen', 'Ġover', 'Ġa', 'Ġ3', 'd', 'Ġglobe', 'ĠThe', 'Ġamount', 'Ġof', 'Ġinformation', 'Ġthat', 'Ġcan', 'Ġbe', 'Ġvisual', 'ized', 'Ġwith', 'Ġthis', 'Ġplatform', 'Ġis', 'Ġoverwhelming', 'Ġand', 'Ġthe', 'ĠG', 'IS', 'Ġbased', 'Ġnavig', 'ational', 'Ġscheme', 'Ġallows', 'Ġto', 'Ġhave', 'Ġgreat', 'Ġflexibility', 'Ġto', 'Ġaccess', 'Ġthe', 'Ġdifferent', 'Ġavailable', 'Ġdata', 'Ġsources', 'ĠFor', 'Ġexample', 'Ġvisual', 'ising', 'Ġhistorical', 'Ġand', 'Ġforecast', 'ed', 'Ġpassenger', 'Ġvolume', 'Ġat', 'Ġstations', 'Ġcould', 'Ġbe', 'Ġvery', 'Ġhelpful', 'Ġwhen', 'Ġoverl', 'aid', 'Ġwith', 'Ġother', 'Ġsocial', 'Ġdata', 'Ġ']\n",
            "input IDs: [0, 10534, 37032, 571, 354, 716, 343, 380, 23687, 155, 417, 38228, 8, 1966, 152, 2225, 924, 5, 10284, 387, 13055, 534, 1729, 1761, 81, 13010, 1533, 3505, 9, 414, 59, 12242, 21830, 81, 10, 155, 417, 7183, 20, 1280, 9, 335, 14, 64, 28, 7133, 1538, 19, 42, 1761, 16, 8642, 8, 5, 272, 1729, 716, 24708, 5033, 3552, 2386, 7, 33, 372, 8243, 7, 899, 5, 430, 577, 414, 1715, 286, 1246, 7133, 3009, 4566, 8, 1914, 196, 4408, 3149, 23, 4492, 115, 28, 182, 7163, 77, 31669, 5526, 19, 97, 592, 414, 1437, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMsUNy8MV8vr"
      },
      "source": [
        "The texts in our dataset have different lengths and we need to truncate them to a fixed length to be able to feed them into the model. Here, we use a histogram to get a distribution of the texts' lengths in our TrainData. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgXsC-InBpKE"
      },
      "source": [
        "## Get length of all texts in TrainData\n",
        "\n",
        "seq_len = [len(i.split()) for i in df['text']]\n",
        "pd.Series(seq_len).hist(bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGm6x5jNCodB"
      },
      "source": [
        "The maximum length of sequences allowed in the RoBERTa model is 512. We need to truncate longer text sequences in the TrainData to 512. According to the histogram of the texts' lengths in TrainData, most of the texts have a length of less than 400. Because of Cuda memory limitations, the max_len parameter of the model is set to 300. However, we lose some information of texts with longer lengths. Texts that have a length of less than this value are padded with a [PAD] token. Therefore, all texts will have the same length. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIlmiMqq5SIj",
        "outputId": "9c754b65-5342-4536-f8eb-d7c19cb2d8b8"
      },
      "source": [
        "## padding/truncating\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "Max_Len = Max_Len\n",
        "print('\\nPadding/truncating all texts to %d values...' % Max_Len)\n",
        "input_ids = pad_sequences(input_ids, maxlen=Max_Len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "# \"post\" indicates that the padding and truncation is being done at the end of the sequence not the begining"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all texts to 300 values...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFGXDA1b5USm"
      },
      "source": [
        "## Create attention masks\n",
        "\n",
        "## The “Attention Mask” is an array of 1s and 0s indicating which tokens are padding and which are actual words\n",
        "attention_masks = []\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYt1SL8t5atk"
      },
      "source": [
        "## splitting: Use 80% for training and 20% for validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, labels,random_state=seed_val, test_size=0.2)\n",
        "train_masks, valid_masks, _, _ = train_test_split(attention_masks, labels, random_state=seed_val, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFfDFDsD5gPX"
      },
      "source": [
        "## Convert the ndarrays into torch tensors, i.e. the format that is acceptable to the model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "valid_inputs = torch.tensor(valid_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "valid_labels = torch.tensor(valid_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "valid_masks = torch.tensor(valid_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqN_ig_F5kIa"
      },
      "source": [
        "## Create the DataLoaders\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = batch_size      \n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg97nuA15qZc"
      },
      "source": [
        "## Load RobertaForSequenceClassification\n",
        "# This is the RoBERTa model with an added single linear layer on top for classification task\n",
        "\n",
        "import random\n",
        "import gc\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\",num_labels = 20, output_attentions = False, output_hidden_states = False,)\n",
        "model.cuda()\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eefdJFgM5wMc"
      },
      "source": [
        "## optimizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "optimizer = AdamW(model.parameters(), lr = lr, eps = eps) \n",
        "epochs = epochs\n",
        "## Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "## Create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVfbJy_451nj"
      },
      "source": [
        "## Function to calculate the accuracy \n",
        "def accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcoBINZjnRED",
        "outputId": "73baf876-c4c8-413e-c7ca-6aed600efcf9"
      },
      "source": [
        "## Training\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('Epoch {:} / {:}'.format(epoch_i + 1, epochs))\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}  Loss: {}'.format( step, len(train_dataloader), loss))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()        \n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # This could prevent the \"exploding gradients\" problem\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Updates the learning rate\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "\n",
        "## Evaluation on the Validation set\n",
        "    print(\"Running Validation...\")\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "    print(\" Validation Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 / 4\n",
            "  Batch   100  of  4,800  Loss: 1.7694305181503296\n",
            "  Batch   200  of  4,800  Loss: 1.7775938510894775\n",
            "  Batch   300  of  4,800  Loss: 0.9623749852180481\n",
            "  Batch   400  of  4,800  Loss: 0.8060488700866699\n",
            "  Batch   500  of  4,800  Loss: 2.200165271759033\n",
            "  Batch   600  of  4,800  Loss: 0.6863747835159302\n",
            "  Batch   700  of  4,800  Loss: 0.694191575050354\n",
            "  Batch   800  of  4,800  Loss: 0.7887923717498779\n",
            "  Batch   900  of  4,800  Loss: 0.3921346068382263\n",
            "  Batch 1,000  of  4,800  Loss: 1.0035321712493896\n",
            "  Batch 1,100  of  4,800  Loss: 0.6936561465263367\n",
            "  Batch 1,200  of  4,800  Loss: 0.33959072828292847\n",
            "  Batch 1,300  of  4,800  Loss: 0.8235193490982056\n",
            "  Batch 1,400  of  4,800  Loss: 0.22305309772491455\n",
            "  Batch 1,500  of  4,800  Loss: 0.13993532955646515\n",
            "  Batch 1,600  of  4,800  Loss: 0.2875683903694153\n",
            "  Batch 1,700  of  4,800  Loss: 0.3189179003238678\n",
            "  Batch 1,800  of  4,800  Loss: 0.13405248522758484\n",
            "  Batch 1,900  of  4,800  Loss: 0.45669588446617126\n",
            "  Batch 2,000  of  4,800  Loss: 1.6488937139511108\n",
            "  Batch 2,100  of  4,800  Loss: 0.5214220285415649\n",
            "  Batch 2,200  of  4,800  Loss: 0.5854884386062622\n",
            "  Batch 2,300  of  4,800  Loss: 0.5208834409713745\n",
            "  Batch 2,400  of  4,800  Loss: 0.47981610894203186\n",
            "  Batch 2,500  of  4,800  Loss: 1.090120553970337\n",
            "  Batch 2,600  of  4,800  Loss: 1.0448055267333984\n",
            "  Batch 2,700  of  4,800  Loss: 0.5746455192565918\n",
            "  Batch 2,800  of  4,800  Loss: 1.221406102180481\n",
            "  Batch 2,900  of  4,800  Loss: 0.10389745235443115\n",
            "  Batch 3,000  of  4,800  Loss: 0.4476802349090576\n",
            "  Batch 3,100  of  4,800  Loss: 0.4601355493068695\n",
            "  Batch 3,200  of  4,800  Loss: 0.5389028191566467\n",
            "  Batch 3,300  of  4,800  Loss: 0.8419785499572754\n",
            "  Batch 3,400  of  4,800  Loss: 0.8507210612297058\n",
            "  Batch 3,500  of  4,800  Loss: 0.7737098932266235\n",
            "  Batch 3,600  of  4,800  Loss: 0.4140937924385071\n",
            "  Batch 3,700  of  4,800  Loss: 0.5429799556732178\n",
            "  Batch 3,800  of  4,800  Loss: 0.6546029448509216\n",
            "  Batch 3,900  of  4,800  Loss: 1.0030587911605835\n",
            "  Batch 4,000  of  4,800  Loss: 1.2254759073257446\n",
            "  Batch 4,100  of  4,800  Loss: 0.21007093787193298\n",
            "  Batch 4,200  of  4,800  Loss: 0.2818126082420349\n",
            "  Batch 4,300  of  4,800  Loss: 1.1606825590133667\n",
            "  Batch 4,400  of  4,800  Loss: 1.209747314453125\n",
            "  Batch 4,500  of  4,800  Loss: 0.861894965171814\n",
            "  Batch 4,600  of  4,800  Loss: 0.40090394020080566\n",
            "  Batch 4,700  of  4,800  Loss: 0.48635172843933105\n",
            "  Average training loss: 0.73\n",
            "Running Validation...\n",
            " Validation Accuracy: 0.8203\n",
            "Epoch 2 / 4\n",
            "  Batch   100  of  4,800  Loss: 0.5301839113235474\n",
            "  Batch   200  of  4,800  Loss: 0.45094433426856995\n",
            "  Batch   300  of  4,800  Loss: 0.023263076320290565\n",
            "  Batch   400  of  4,800  Loss: 0.22534504532814026\n",
            "  Batch   500  of  4,800  Loss: 0.3123776316642761\n",
            "  Batch   600  of  4,800  Loss: 0.5196977853775024\n",
            "  Batch   700  of  4,800  Loss: 0.24410319328308105\n",
            "  Batch   800  of  4,800  Loss: 0.49395695328712463\n",
            "  Batch   900  of  4,800  Loss: 0.096804179251194\n",
            "  Batch 1,000  of  4,800  Loss: 0.2582470774650574\n",
            "  Batch 1,100  of  4,800  Loss: 0.25036361813545227\n",
            "  Batch 1,200  of  4,800  Loss: 0.4484400749206543\n",
            "  Batch 1,300  of  4,800  Loss: 0.6786739826202393\n",
            "  Batch 1,400  of  4,800  Loss: 0.973772406578064\n",
            "  Batch 1,500  of  4,800  Loss: 0.7673420906066895\n",
            "  Batch 1,600  of  4,800  Loss: 0.7202544808387756\n",
            "  Batch 1,700  of  4,800  Loss: 0.08670095354318619\n",
            "  Batch 1,800  of  4,800  Loss: 0.34966346621513367\n",
            "  Batch 1,900  of  4,800  Loss: 0.041503727436065674\n",
            "  Batch 2,000  of  4,800  Loss: 0.3045847415924072\n",
            "  Batch 2,100  of  4,800  Loss: 0.5076509714126587\n",
            "  Batch 2,200  of  4,800  Loss: 0.41081804037094116\n",
            "  Batch 2,300  of  4,800  Loss: 0.4397410750389099\n",
            "  Batch 2,400  of  4,800  Loss: 0.17564623057842255\n",
            "  Batch 2,500  of  4,800  Loss: 0.13678960502147675\n",
            "  Batch 2,600  of  4,800  Loss: 0.06853778660297394\n",
            "  Batch 2,700  of  4,800  Loss: 0.5863076448440552\n",
            "  Batch 2,800  of  4,800  Loss: 0.4365476071834564\n",
            "  Batch 2,900  of  4,800  Loss: 0.5991493463516235\n",
            "  Batch 3,000  of  4,800  Loss: 0.1367451399564743\n",
            "  Batch 3,100  of  4,800  Loss: 0.495368629693985\n",
            "  Batch 3,200  of  4,800  Loss: 0.07717783749103546\n",
            "  Batch 3,300  of  4,800  Loss: 0.2953040599822998\n",
            "  Batch 3,400  of  4,800  Loss: 1.0676769018173218\n",
            "  Batch 3,500  of  4,800  Loss: 1.1329190731048584\n",
            "  Batch 3,600  of  4,800  Loss: 0.6146789193153381\n",
            "  Batch 3,700  of  4,800  Loss: 0.5642706155776978\n",
            "  Batch 3,800  of  4,800  Loss: 0.03776836395263672\n",
            "  Batch 3,900  of  4,800  Loss: 0.2703389525413513\n",
            "  Batch 4,000  of  4,800  Loss: 0.12812232971191406\n",
            "  Batch 4,100  of  4,800  Loss: 0.7701990008354187\n",
            "  Batch 4,200  of  4,800  Loss: 0.697953462600708\n",
            "  Batch 4,300  of  4,800  Loss: 0.6633460521697998\n",
            "  Batch 4,400  of  4,800  Loss: 0.9009652137756348\n",
            "  Batch 4,500  of  4,800  Loss: 0.21517185866832733\n",
            "  Batch 4,600  of  4,800  Loss: 0.44600701332092285\n",
            "  Batch 4,700  of  4,800  Loss: 0.3532159924507141\n",
            "  Average training loss: 0.47\n",
            "Running Validation...\n",
            " Validation Accuracy: 0.8453\n",
            "Epoch 3 / 4\n",
            "  Batch   100  of  4,800  Loss: 0.06254532188177109\n",
            "  Batch   200  of  4,800  Loss: 0.8237606883049011\n",
            "  Batch   300  of  4,800  Loss: 0.03580375388264656\n",
            "  Batch   400  of  4,800  Loss: 0.22331678867340088\n",
            "  Batch   500  of  4,800  Loss: 0.2266416996717453\n",
            "  Batch   600  of  4,800  Loss: 0.1876339614391327\n",
            "  Batch   700  of  4,800  Loss: 0.5514892339706421\n",
            "  Batch   800  of  4,800  Loss: 0.06427004933357239\n",
            "  Batch   900  of  4,800  Loss: 0.049149565398693085\n",
            "  Batch 1,000  of  4,800  Loss: 0.02534569427371025\n",
            "  Batch 1,100  of  4,800  Loss: 0.985683798789978\n",
            "  Batch 1,200  of  4,800  Loss: 0.3385236859321594\n",
            "  Batch 1,300  of  4,800  Loss: 0.47701358795166016\n",
            "  Batch 1,400  of  4,800  Loss: 0.013517407700419426\n",
            "  Batch 1,500  of  4,800  Loss: 0.4444666802883148\n",
            "  Batch 1,600  of  4,800  Loss: 0.12285134941339493\n",
            "  Batch 1,700  of  4,800  Loss: 0.1290799081325531\n",
            "  Batch 1,800  of  4,800  Loss: 0.5306199789047241\n",
            "  Batch 1,900  of  4,800  Loss: 0.07356851547956467\n",
            "  Batch 2,000  of  4,800  Loss: 0.38246411085128784\n",
            "  Batch 2,100  of  4,800  Loss: 0.3891600966453552\n",
            "  Batch 2,200  of  4,800  Loss: 0.008325159549713135\n",
            "  Batch 2,300  of  4,800  Loss: 1.0895774364471436\n",
            "  Batch 2,400  of  4,800  Loss: 0.33029764890670776\n",
            "  Batch 2,500  of  4,800  Loss: 0.03351139277219772\n",
            "  Batch 2,600  of  4,800  Loss: 0.19459643959999084\n",
            "  Batch 2,700  of  4,800  Loss: 0.25492945313453674\n",
            "  Batch 2,800  of  4,800  Loss: 0.3292106091976166\n",
            "  Batch 2,900  of  4,800  Loss: 0.5426841378211975\n",
            "  Batch 3,000  of  4,800  Loss: 0.19201743602752686\n",
            "  Batch 3,100  of  4,800  Loss: 0.5845785140991211\n",
            "  Batch 3,200  of  4,800  Loss: 0.20979049801826477\n",
            "  Batch 3,300  of  4,800  Loss: 0.7018731832504272\n",
            "  Batch 3,400  of  4,800  Loss: 0.07914473861455917\n",
            "  Batch 3,500  of  4,800  Loss: 0.009477290324866772\n",
            "  Batch 3,600  of  4,800  Loss: 0.12536853551864624\n",
            "  Batch 3,700  of  4,800  Loss: 0.34294241666793823\n",
            "  Batch 3,800  of  4,800  Loss: 0.06224312260746956\n",
            "  Batch 3,900  of  4,800  Loss: 0.05158091336488724\n",
            "  Batch 4,000  of  4,800  Loss: 0.034564461559057236\n",
            "  Batch 4,100  of  4,800  Loss: 0.7315157055854797\n",
            "  Batch 4,200  of  4,800  Loss: 0.027673205360770226\n",
            "  Batch 4,300  of  4,800  Loss: 0.47613435983657837\n",
            "  Batch 4,400  of  4,800  Loss: 0.6890034675598145\n",
            "  Batch 4,500  of  4,800  Loss: 0.3540789783000946\n",
            "  Batch 4,600  of  4,800  Loss: 0.015379284508526325\n",
            "  Batch 4,700  of  4,800  Loss: 0.14701536297798157\n",
            "  Average training loss: 0.34\n",
            "Running Validation...\n",
            " Validation Accuracy: 0.8473\n",
            "Epoch 4 / 4\n",
            "  Batch   100  of  4,800  Loss: 0.4588910639286041\n",
            "  Batch   200  of  4,800  Loss: 0.3163009285926819\n",
            "  Batch   300  of  4,800  Loss: 0.38501426577568054\n",
            "  Batch   400  of  4,800  Loss: 0.021204914897680283\n",
            "  Batch   500  of  4,800  Loss: 0.43960705399513245\n",
            "  Batch   600  of  4,800  Loss: 0.3083406090736389\n",
            "  Batch   700  of  4,800  Loss: 0.24424263834953308\n",
            "  Batch   800  of  4,800  Loss: 0.26864105463027954\n",
            "  Batch   900  of  4,800  Loss: 0.5413205027580261\n",
            "  Batch 1,000  of  4,800  Loss: 0.08133639395236969\n",
            "  Batch 1,100  of  4,800  Loss: 0.08961834758520126\n",
            "  Batch 1,200  of  4,800  Loss: 0.15447500348091125\n",
            "  Batch 1,300  of  4,800  Loss: 0.19604425132274628\n",
            "  Batch 1,400  of  4,800  Loss: 0.29654908180236816\n",
            "  Batch 1,500  of  4,800  Loss: 0.011488412506878376\n",
            "  Batch 1,600  of  4,800  Loss: 0.7508957386016846\n",
            "  Batch 1,700  of  4,800  Loss: 0.2846136689186096\n",
            "  Batch 1,800  of  4,800  Loss: 0.1953880339860916\n",
            "  Batch 1,900  of  4,800  Loss: 0.15271756052970886\n",
            "  Batch 2,000  of  4,800  Loss: 0.026712605729699135\n",
            "  Batch 2,100  of  4,800  Loss: 0.07835911214351654\n",
            "  Batch 2,200  of  4,800  Loss: 0.31432050466537476\n",
            "  Batch 2,300  of  4,800  Loss: 0.19866056740283966\n",
            "  Batch 2,400  of  4,800  Loss: 0.87724369764328\n",
            "  Batch 2,500  of  4,800  Loss: 0.04365341365337372\n",
            "  Batch 2,600  of  4,800  Loss: 0.2544527053833008\n",
            "  Batch 2,700  of  4,800  Loss: 0.33096063137054443\n",
            "  Batch 2,800  of  4,800  Loss: 0.6550400853157043\n",
            "  Batch 2,900  of  4,800  Loss: 0.09834278374910355\n",
            "  Batch 3,000  of  4,800  Loss: 0.0035086802672594786\n",
            "  Batch 3,100  of  4,800  Loss: 0.030476484447717667\n",
            "  Batch 3,200  of  4,800  Loss: 0.12662675976753235\n",
            "  Batch 3,300  of  4,800  Loss: 1.5309064388275146\n",
            "  Batch 3,400  of  4,800  Loss: 0.4513916075229645\n",
            "  Batch 3,500  of  4,800  Loss: 0.17666485905647278\n",
            "  Batch 3,600  of  4,800  Loss: 0.014900103211402893\n",
            "  Batch 3,700  of  4,800  Loss: 0.00623571639880538\n",
            "  Batch 3,800  of  4,800  Loss: 0.17454366385936737\n",
            "  Batch 3,900  of  4,800  Loss: 0.1419738531112671\n",
            "  Batch 4,000  of  4,800  Loss: 0.5208526849746704\n",
            "  Batch 4,100  of  4,800  Loss: 1.0767111778259277\n",
            "  Batch 4,200  of  4,800  Loss: 0.058208249509334564\n",
            "  Batch 4,300  of  4,800  Loss: 0.001943356590345502\n",
            "  Batch 4,400  of  4,800  Loss: 0.030805343762040138\n",
            "  Batch 4,500  of  4,800  Loss: 0.5749291777610779\n",
            "  Batch 4,600  of  4,800  Loss: 0.18616703152656555\n",
            "  Batch 4,700  of  4,800  Loss: 0.42423033714294434\n",
            "  Average training loss: 0.23\n",
            "Running Validation...\n",
            " Validation Accuracy: 0.8502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr41E-0Mjs8V"
      },
      "source": [
        "## Saving/Loading the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYcxO6QtjwCh"
      },
      "source": [
        "## Create the output directory \n",
        "output_dir = './model_save_Bahareh/'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Takes care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "## Save the fine-tunned model on google drive\n",
        "!cp -r ./model_save_Bahareh/ \"/content/drive/MyDrive/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYTnwJdpQ73K"
      },
      "source": [
        "## Load the fine-tunned model if needed\n",
        "model = RobertaForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(output_dir)\n",
        "model.to(device)\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydnei6GR3y4c"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQFw6Kl06GGP"
      },
      "source": [
        "## TestData preparation\n",
        "\n",
        "texts2 = df2.text.values\n",
        "\n",
        "input_ids2 = []\n",
        "for text in texts2:\n",
        "    encoded_text2 = tokenizer.encode(text, add_special_tokens = True,)\n",
        "    input_ids2.append(encoded_text2)\n",
        "input_ids2 = pad_sequences(input_ids2, maxlen=Max_Len, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "attention_masks2 = []\n",
        "for seq in input_ids2:\n",
        "  seq_mask2 = [float(i>0) for i in seq]\n",
        "  attention_masks2.append(seq_mask2) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids2)\n",
        "prediction_masks = torch.tensor(attention_masks2)\n",
        "\n",
        "batch_size = batch_size  \n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPcurNeE6htu"
      },
      "source": [
        "## Prediction on TestData\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  b_input_ids, b_input_mask = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "  logits = outputs[0]\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  \n",
        "  predictions.append(logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gatu-wcw6z-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa6dbe8-fbea-4708-e3d4-6fefb4ea575f"
      },
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16,  4, 10, ..., 10, 16,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfYERb_62TE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "38bf1731-3466-4b84-9a18-f3a6bd853dcf"
      },
      "source": [
        "flat_predictions = pd.DataFrame(flat_predictions, columns=['label_predicted'])\n",
        "flat_predictions.to_csv('predictions_Bahareh.csv')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('predictions_Bahareh.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5367cdad-186a-4306-8ebf-160ff4381039\", \"predictions.csv\", 106702)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}